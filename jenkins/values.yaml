master:
  # to prevent the jenkins-ui-test pod being created
  testEnabled: false
  # Use deterministic version and not "lts", which is pretty much the same as "latest".
  # Note: When updating, check if PATH of image still matches the one listed in "containerEnv"
  tag: 2.249.3-lts-jdk11

  serviceType: NodePort
  nodePort: 9090

  additionalPlugins:
    - docker-workflow:1.25
    - docker-plugin:1.2.1
    - job-dsl:1.77
    - pipeline-utility-steps:2.6.1
    - junit:1.44
    - scm-manager:1.5.0

  # This would be great to not install every plugin again on startup.
  # BUT: This also leads to CASC being ignored.
  # initializeOnce: true

  # Don't use master for builds
  numExecutors: 0

  JCasC:
    configScripts:
      # TODO use SCMM user secret keys for username and password
      scmm-credentials: |
        credentials:
          system:
            domainCredentials:
            - credentials:
              - usernamePassword:
                  id: "scmm-user"
                  username: "${USERNAME}"
                  password: "${PASSWORD}"
                  description: "Credentials for accessing SCM-Manager"
                  scope: GLOBAL

      # TODO could we use the SCMM source here?
      # These URLS could be helpful:
      # http://localhost:9090/job/petclinic-plain/config.xml
      # http://localhost:9090//plugin/job-dsl/api-viewer/index.html#path/multibranchPipelineJob-branchSources
      # For now using "scm-manager" in JobDSL leads to an error when CASC is applied: 
      # "No such property: scm for class: javaposse.jobdsl.plugin.structs.DescribableListContext"
      # This is probably because "scm-manager" is invalid groovy syntax.
      # See https://github.com/jenkinsci/scm-manager-plugin/blob/1.4.0/src/main/java/com/cloudogu/scmmanager/scm/ScmManagerSource.java
      # This might be fixed in a later SCMM Plugin for Jenkins
      init-job: |
        jenkins:
          systemMessage: "Seeding init jobs"
        jobs:
          - script: |
              multibranchPipelineJob('fluxV1-petclinic-plain') {
                  branchSources {
                      git {
                          id('fluxV1-petclinic-plain')
                          remote('http://scmm-scm-manager:9091/scm/repo/fluxv1/petclinic-plain')
                          credentialsId('scmm-user')
                      }
                  }
              }
          - script: |
              multibranchPipelineJob('fluxv1-nginx') {
                  branchSources {
                      git {
                          id('fluxv1-nginx')
                          remote('http://scmm-scm-manager:9091/scm/repo/fluxv1/nginx-helm')
                          credentialsId('scmm-user')
                      }
                  }
              }
          - script: |
              multibranchPipelineJob('fluxv2-petclinic-plain') {
                  branchSources {
                      git {
                          id('fluxv2-petclinic-plain')
                          remote('http://scmm-scm-manager:9091/scm/repo/fluxv2/petclinic-plain')
                          credentialsId('scmm-user')
                      }
                  }
              }
          - script: |
              multibranchPipelineJob('argocd-petclinic-plain') {
                  branchSources {
                      git {
                          id('argocd-petclinic-plain')
                          remote('http://scmm-scm-manager:9091/scm/repo/argocd/petclinic-plain')
                          credentialsId('scmm-user')
                      }
                  }
              }

  sidecars:
    configAutoReload:
      enabled: false

  admin:
    # Use reproducible admin password from secret. Change there, if necessary.
    existingSecret: jenkins-credentials

  containerEnv:
    - name: SECRETS
      # The files in this folders can be used as ${variable} in CasC credentials
      # Default /run/secrets results in "read-only file system"
      value: /secrets/jenkins

persistence:
  volumes:
    - name: scmm-user
      secret:
        secretName: gitops-scmm

  mounts:
    - name: scmm-user
      # Use k8s secret as jenkins credentials.
      # https://github.com/jenkinsci/configuration-as-code-plugin/blob/master/docs/features/secrets.adoc#kubernetes-secrets
      mountPath: /secrets/jenkins
      readOnly: true

agent:
  # We need JDK11 for our PetClinic example
  tag: "4.6-1-jdk11"
  # In our local playground infrastructure builds are run in agent containers (pods). During the builds, more
  # containers are started via the Jenkins Docker Plugin (on the same docker host).
  # This leads to a scenario where the agent container tries to mount its filesystem into another container.
  # The docker host is only able to realize this mounts when the mounted paths are the same inside and outside the
  # containers.
  # So as a workaround, we provide the path inside the container also outside the container.
  # The /tmp folder is a good choice, because it is writable for all users on the host.
  # One disadvantage is, that /tmp is deleted when the host shuts down. Which might slow down builds
  # A different option would be to link the workspace into this repo.
  # If we should ever want to implement this, the logic can be reused from Git History:
  # https://github.com/cloudogu/k8s-gitops-playground/blob/61e033/scripts/apply.sh#L211-L235
  # We mount the same PATH as a hostPath. See bellow.
  workingDir: "/tmp/k8s-gitops-playground-jenkins-agent"
  # Number of concurrent builds. Keep it low to avoid high CPU load.
  containerCap: 1
  customJenkinsLabels: [ 'docker' ]
  resources:
    limits:
      cpu: "1"
      memory: "1Gi"
  volumes:
    - type: HostPath
      # See workingDir
      hostPath: /tmp/k8s-gitops-playground-jenkins-agent
      mountPath: /tmp/k8s-gitops-playground-jenkins-agent
    - type: HostPath
      # For this demo, allow jenkins master to access docker client
      hostPath: /var/run/docker.sock
      mountPath: /var/run/docker.sock
    - type: HostPath
      # Use the local docker binary.
      # This might cause problems on some host: Risk of missing libraries because docker might be linked dynamically
      # and libraries might be missing inside the agent container.
      # An alternative would be to download a statically linked docker container and place it into a PVC.
      # However, the agent does not seem to provide the option for initContainers.
      # We could use the master's initContainer an also write it to a HostPath (in /tmp)
      # But this is more complicated and time consuming.
      # If we should ever change our mind, the logic for downloading the docker client can be reused from Git History:
      # https://github.com/cloudogu/k8s-gitops-playground/blob/72e644/jenkins/values.yaml#L128-L139
      hostPath: /usr/bin/docker
      mountPath: /usr/bin/docker
  # Controls how agent pods are retained after the Jenkins build completes
  # Not in Jenkins but in K8s. Helpful for debugging
  # In order to get rid of those many "default-xyz" pod use: kubectl delete pod -l jenkins/jenkins-jenkins-slave=true
  #podRetention: "OnFailure"

